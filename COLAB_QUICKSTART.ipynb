{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f7a6eac",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee38e1",
   "metadata": {},
   "source": [
    "## üß© Y√™u c·∫ßu ph·ª• thu·ªôc (Dependency) cho Google Colab\n",
    "\n",
    "ƒê·ªÉ ch·∫°y d·ª± √°n ComparisonDetector ·ªïn ƒë·ªãnh tr√™n Google Colab, vui l√≤ng ƒë·∫£m b·∫£o c√°c y√™u c·∫ßu sau:\n",
    "\n",
    "- TensorFlow: `tensorflow==2.19.0` (ch·∫°y ·ªü ch·∫ø ƒë·ªô `tf.compat.v1`, t·∫Øt eager)\n",
    "- Slim: `tf_slim==1.1.0` (thay th·∫ø `tf.contrib.slim`)\n",
    "- NumPy: `numpy==1.26.4` (tr√°nh xung ƒë·ªôt ABI v·ªõi OpenCV v√† TF)\n",
    "- OpenCV: `opencv-python-headless==4.7.0.72` (kh√¥ng d√πng b·∫£n c√≥ GUI)\n",
    "- Khoa h·ªçc d·ªØ li·ªáu: `scikit-image==0.21.0`, `scipy==1.11.4`, `matplotlib==3.7.3`, `tqdm==4.66.4`\n",
    "\n",
    "L∆∞u √Ω quan tr·ªçng:\n",
    "\n",
    "- Kh√¥ng c√†i `tensorflow-io-gcs-filesystem` (kh√¥ng t∆∞∆°ng th√≠ch v·ªõi Python 3.12 tr√™n Colab).\n",
    "- G·ª° c√°c g√≥i c√≥ s·∫µn tr√™n Colab n·∫øu g√¢y xung ƒë·ªôt: `jax`, `jaxlib`, `albumentations`, `albucore`, `pytensor`, `shap`, `opencv-python`, `opencv-contrib-python`.\n",
    "- ∆Øu ti√™n d√πng b√°nh xe (wheels) b·∫±ng c·ªù `--prefer-binary` ƒë·ªÉ tr√°nh build t·ª´ source.\n",
    "\n",
    "Sau ƒë√≥, c√†i ƒë·∫∑t theo Cell 2 ƒë·ªÉ thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng ph√π h·ª£p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51b24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C√†i ƒë·∫∑t dependencies ·ªïn ƒë·ªãnh cho Colab (t·ªëi ∆∞u t·ªëc ƒë·ªô v√† tr√°nh xung ƒë·ªôt)\n",
    "# 1) G·ª° c√°c g√≥i kh√¥ng c·∫ßn thi·∫øt ho·∫∑c g√¢y xung ƒë·ªôt v·ªõi phi√™n b·∫£n pin c·ªßa d·ª± √°n\n",
    "!pip uninstall -y -q opencv-python opencv-contrib-python opencv-python-headless jax jaxlib shap albumentations albucore pytensor || true\n",
    "\n",
    "# 2) C√†i ƒë·∫∑t stack t∆∞∆°ng th√≠ch v·ªõi TensorFlow 2.19 (kh√¥ng c√†i tensorflow-io-gcs-filesystem)\n",
    "#    D√πng --prefer-binary ƒë·ªÉ ∆∞u ti√™n wheels (nhanh h∆°n, kh√¥ng build t·ª´ source)\n",
    "PIP_FLAGS = \"--prefer-binary\"\n",
    "!pip install -q {PIP_FLAGS} tensorflow==2.19.0 tf_slim==1.1.0\n",
    "!pip install -q {PIP_FLAGS} numpy==1.26.4 opencv-python-headless==4.7.0.72\n",
    "!pip install -q {PIP_FLAGS} scikit-image==0.21.0 scipy==1.11.4 matplotlib==3.7.3 tqdm==4.66.4\n",
    "\n",
    "# 3) In x√°c nh·∫≠n\n",
    "print(\"‚úì ƒê√£ c√†i ƒë·∫∑t dependencies t∆∞∆°ng th√≠ch v√† g·ª° xung ƒë·ªôt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d538d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra c√°c g√≥i g√¢y xung ƒë·ªôt ƒë√£ ƒë∆∞·ª£c g·ª° b·ªè v√† phi√™n b·∫£n hi·ªán t·∫°i\n",
    "import pkgutil, sys\n",
    "\n",
    "def is_installed(pkg):\n",
    "    return pkgutil.find_loader(pkg) is not None\n",
    "\n",
    "check_list = [\n",
    "    (\"numpy\", \"1.26.4\"),\n",
    "    (\"cv2\", \"4.7.0.72\"),\n",
    "]\n",
    "\n",
    "print(\"\\n=== Version check ===\")\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(\"numpy:\", np.__version__)\n",
    "except Exception as e:\n",
    "    print(\"numpy not found:\", e)\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "    print(\"opencv-python-headless (cv2):\", cv2.__version__)\n",
    "except Exception as e:\n",
    "    print(\"cv2 not found:\", e)\n",
    "\n",
    "# C·∫£nh b√°o c√°c g√≥i kh√¥ng c·∫ßn thi·∫øt n·∫øu v·∫´n c√≤n trong m√¥i tr∆∞·ªùng\n",
    "maybe_conflicts = [\"jax\", \"jaxlib\", \"albumentations\", \"albucore\", \"pytensor\", \"shap\", \"opencv_python\", \"opencv_contrib_python\"]\n",
    "leftovers = [p for p in maybe_conflicts if is_installed(p.replace('-', '_'))]\n",
    "if leftovers:\n",
    "    print(\"\\nC·∫£nh b√°o: c√°c g√≥i sau v·∫´n t·ªìn t·∫°i v√† c√≥ th·ªÉ g√¢y c·∫£nh b√°o ph·ª• thu·ªôc:\")\n",
    "    for p in leftovers:\n",
    "        print(\"-\", p)\n",
    "    print(\"N·∫øu kh√¥ng d√πng ch√∫ng, h√£y g·ª° b·∫±ng: !pip uninstall -y\", \" \".join(leftovers))\n",
    "else:\n",
    "    print(\"\\nKh√¥ng c√≤n g√≥i xung ƒë·ªôt ƒë√°ng k·ªÉ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d423cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ki·ªÉm tra phi√™n b·∫£n v√† disable eager execution\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "print(f\"TensorFlow: {tf.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")\n",
    "print(f\"Eager execution: {tf.executing_eagerly()}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724eae0e",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Clone repo v√† setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5f5a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone repo t·ª´ GitHub\n",
    "!git clone https://github.com/dungdinhhaha/AIDetect.git\n",
    "%cd AIDetect\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf15fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (ƒë·ªÉ l∆∞u model v√† data)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c cho data (n·∫øu ch∆∞a c√≥)\n",
    "!mkdir -p /content/data/tct\n",
    "print(\"‚úì Google Drive mounted and data folder created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8a03ab",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Chu·∫©n b·ªã d·ªØ li·ªáu\n",
    "\n",
    "**T√πy ch·ªçn A**: Upload TFRecord t·ª´ Drive\n",
    "```python\n",
    "!cp /content/drive/MyDrive/your-data/*.tfrecord /content/data/tct/\n",
    "!cp /content/drive/MyDrive/your-data/labels.tsv /content/data/tct/\n",
    "```\n",
    "\n",
    "**T√πy ch·ªçn B**: S·ª≠ d·ª•ng data m·∫´u (n·∫øu c√≥ trong repo)\n",
    "```python\n",
    "# Uncomment n·∫øu repo c√≥ sample data\n",
    "# !cp -r sample_data/* /content/data/tct/\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d5d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THAY ƒê·ªîI ƒë∆∞·ªùng d·∫´n n√†y t√πy theo v·ªã tr√≠ data c·ªßa b·∫°n tr√™n Drive\n",
    "# V√≠ d·ª•: n·∫øu data ·ªü MyDrive/ComparisonDetector_Data/\n",
    "\n",
    "# !cp /content/drive/MyDrive/ComparisonDetector_Data/*.tfrecord /content/data/tct/\n",
    "# !cp /content/drive/MyDrive/ComparisonDetector_Data/labels.tsv /content/data/tct/\n",
    "\n",
    "# Ki·ªÉm tra data ƒë√£ c√≥ ch∆∞a\n",
    "!ls -lh /content/data/tct/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd82c1fc",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ C·∫•u h√¨nh training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38280237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C·∫≠p nh·∫≠t config ƒë·ªÉ tr·ªè ƒë·∫øn data path Colab\n",
    "config_content = '''\n",
    "import os\n",
    "\n",
    "class Config:\n",
    "    # Paths\n",
    "    DATA_DIR = \"/content/data/tct\"  # Colab data path\n",
    "    MODLE_DIR = \"/content/drive/MyDrive/comparison_detector_models\"  # L∆∞u model v√†o Drive\n",
    "    CHECKPOINT_DIR = None  # Set path n·∫øu c√≥ pretrained checkpoint\n",
    "    \n",
    "    # Network\n",
    "    NET_NAME = \"resnet_v1_101\"  # ho·∫∑c resnet_v1_50\n",
    "    NUM_CLASS = 12  # 11 classes + 1 background\n",
    "    NUM_SUPPROTS = 3  # S·ªë ·∫£nh reference m·ªói class\n",
    "    ROI_SIZE = 7\n",
    "    \n",
    "    # Training\n",
    "    BATCH_SIZE = 1  # Colab GPU nh·ªè n√™n ƒë·ªÉ 1\n",
    "    EPOCH = 50\n",
    "    LEARNING_RATE = 0.001\n",
    "    MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    BOUNDARY = [30000, 50000]\n",
    "    \n",
    "    # Save\n",
    "    SAVE_EVERY_N_STEP = 500\n",
    "    \n",
    "    # GPU\n",
    "    GPU_GROUPS = [[\"GPU:0\"]]  # Colab single GPU\n",
    "    \n",
    "    # Image preprocessing\n",
    "    PIXEL_MEANS = [123.68, 116.779, 103.939]  # ImageNet mean\n",
    "'''\n",
    "\n",
    "with open('configs/config.py', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "print(\"‚úì Config updated for Colab\")\n",
    "!cat configs/config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be06427",
   "metadata": {},
   "source": [
    "## 5Ô∏è‚É£ Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a172136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ch·∫°y training (s·∫Ω m·∫•t v√†i gi·ªù t√πy dataset)\n",
    "!python tools/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f404512",
   "metadata": {},
   "source": [
    "## 6Ô∏è‚É£ Theo d√µi training v·ªõi TensorBoard (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63aed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/comparison_detector_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b97a0",
   "metadata": {},
   "source": [
    "## 7Ô∏è‚É£ Smoke test (ki·ªÉm tra code kh√¥ng c·∫ßn train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test nhanh import v√† graph build (kh√¥ng c·∫ßn data th·∫≠t)\n",
    "!python tools/smoke_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e949cda7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù L∆∞u √Ω quan tr·ªçng\n",
    "\n",
    "### ‚úÖ Tr∆∞·ªõc khi train\n",
    "1. **GPU Runtime**: ƒê·∫£m b·∫£o ƒë√£ ch·ªçn GPU runtime (T4 tr·ªü l√™n)\n",
    "2. **Data**: Upload TFRecord v√† labels.tsv v√†o `/content/data/tct/`\n",
    "3. **Reference images**: ƒê·∫£m b·∫£o c√≥ th∆∞ m·ª•c `images/` v·ªõi ·∫£nh reference\n",
    "\n",
    "### üîß Troubleshooting\n",
    "\n",
    "**L·ªói \"ModuleNotFoundError: tf.contrib\"**:\n",
    "- ƒê√£ fix b·∫±ng tf_slim, nh∆∞ng n·∫øu v·∫´n g·∫∑p, check l·∫°i cell c√†i ƒë·∫∑t dependencies\n",
    "\n",
    "**L·ªói NumPy/OpenCV ABI**:\n",
    "- ƒê√£ pin NumPy 1.26.4 v√† OpenCV headless 4.7, kh√¥ng n√™n thay ƒë·ªïi\n",
    "\n",
    "**Out of memory**:\n",
    "- Gi·∫£m `BATCH_SIZE` trong config xu·ªëng 1\n",
    "- D√πng ResNet50 thay v√¨ ResNet101\n",
    "\n",
    "### üíæ L∆∞u model\n",
    "- Model t·ª± ƒë·ªông l∆∞u v√†o Drive: `/content/drive/MyDrive/comparison_detector_models/`\n",
    "- Checkpoint m·ªói 500 steps\n",
    "\n",
    "### üìä Monitoring\n",
    "- TensorBoard: xem loss v√† metrics real-time\n",
    "- Logs: check terminal output ƒë·ªÉ debug\n",
    "\n",
    "---\n",
    "\n",
    "**Repo**: https://github.com/dungdinhhaha/AIDetect  \n",
    "**T√°c gi·∫£**: dungdinhhaha | dungdinh542004@gmail.com"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
