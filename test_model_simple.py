"""
Script Ä‘Æ¡n giáº£n Ä‘á»ƒ test model Ä‘Ã£ train
Sá»­ dá»¥ng: python test_model_simple.py
"""

import tensorflow as tf
import numpy as np
from pathlib import Path
from data.loader_tf2 import build_dataset
from configs.config_v2 import IMAGE_SIZE, NUM_CLASSES
import json

def test_model_on_dataset():
    """Test model trÃªn test dataset"""
    
    # 1. Load model
    print("=" * 60)
    print("ğŸ” TESTING MODEL")
    print("=" * 60)
    
    model_path = input("Nháº­p path Ä‘áº¿n model (Enter = best_model.h5): ").strip()
    if not model_path:
        model_path = "trained_models/best_model.h5"
    
    if not Path(model_path).exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y model: {model_path}")
        print("\nğŸ’¡ HÆ°á»›ng dáº«n:")
        print("   1. Download model tá»« Google Drive")
        print("   2. Copy vÃ o folder: trained_models/")
        print("   3. Run láº¡i script nÃ y")
        return
    
    print(f"\nğŸ“¦ Loading model: {model_path}")
    model = tf.keras.models.load_model(model_path)
    print("âœ… Model loaded!")
    print(f"   Input shape: {model.input_shape}")
    print(f"   Output shape: {model.output_shape}")
    
    # 2. Load test dataset
    print(f"\nğŸ“Š Loading test dataset...")
    test_paths = ['tfdata/tct/test.tfrecord']
    
    if not Path(test_paths[0]).exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y test data: {test_paths[0]}")
        print("\nğŸ’¡ Äáº£m báº£o báº¡n cÃ³ file tfdata/tct/test.tfrecord")
        return
    
    test_ds = build_dataset(
        test_paths, 
        image_size=IMAGE_SIZE, 
        batch_size=4,
        is_training=False
    )
    
    # Map to extract labels
    def extract_label(img, tgt):
        # Get first label for each image (simplified classification)
        return img, tgt['labels'][:, 0]
    
    test_ds = test_ds.map(extract_label).take(50)  # Take 50 batches = 200 images
    
    # 3. Evaluate
    print(f"\nâš™ï¸  Evaluating on test set...")
    results = model.evaluate(test_ds, verbose=1)
    
    test_loss = results[0]
    test_accuracy = results[1]
    
    print("\n" + "=" * 60)
    print("ğŸ“Š TEST RESULTS")
    print("=" * 60)
    print(f"Loss:     {test_loss:.4f}")
    print(f"Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    print("=" * 60)
    
    # 4. Save results
    results_dict = {
        'model_path': str(model_path),
        'test_loss': float(test_loss),
        'test_accuracy': float(test_accuracy),
        'num_batches': 50,
        'batch_size': 4,
        'total_images_tested': 200
    }
    
    output_path = Path('test_results.json')
    with open(output_path, 'w') as f:
        json.dump(results_dict, f, indent=2)
    
    print(f"\nâœ… Results saved to: {output_path}")
    
    # 5. Sample predictions
    print(f"\nğŸ”® Running sample predictions...")
    for images, labels in test_ds.take(1):
        predictions = model.predict(images, verbose=0)
        
        print("\nSample predictions (first 4 images):")
        print("-" * 60)
        for i in range(min(4, len(images))):
            pred_class = np.argmax(predictions[i])
            pred_conf = predictions[i][pred_class]
            true_class = int(labels[i].numpy())
            
            status = "âœ…" if pred_class == true_class else "âŒ"
            print(f"{status} Image {i+1}:")
            print(f"   True class:      {true_class}")
            print(f"   Predicted class: {pred_class}")
            print(f"   Confidence:      {pred_conf:.2%}")
            print()
    
    print("=" * 60)
    print("âœ… Testing completed!")
    print("=" * 60)


def test_single_image():
    """Test model trÃªn 1 áº£nh Ä‘Æ¡n láº»"""
    
    print("=" * 60)
    print("ğŸ–¼ï¸  TESTING ON SINGLE IMAGE")
    print("=" * 60)
    
    # Load model
    model_path = input("Nháº­p path Ä‘áº¿n model (Enter = best_model.h5): ").strip()
    if not model_path:
        model_path = "trained_models/best_model.h5"
    
    if not Path(model_path).exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y model: {model_path}")
        return
    
    print(f"\nğŸ“¦ Loading model: {model_path}")
    model = tf.keras.models.load_model(model_path)
    print("âœ… Model loaded!")
    
    # Load image
    from PIL import Image
    
    image_path = input("\nNháº­p path Ä‘áº¿n áº£nh test: ").strip()
    if not Path(image_path).exists():
        print(f"âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh: {image_path}")
        return
    
    print(f"\nğŸ–¼ï¸  Loading image: {image_path}")
    img = Image.open(image_path).convert('RGB')
    
    # Preprocess
    img_resized = img.resize(IMAGE_SIZE)
    img_array = np.array(img_resized) / 255.0  # Normalize to [0, 1]
    img_array = np.expand_dims(img_array, 0)  # Add batch dimension
    
    print(f"   Original size: {img.size}")
    print(f"   Resized to: {IMAGE_SIZE}")
    print(f"   Array shape: {img_array.shape}")
    
    # Predict
    print(f"\nğŸ”® Predicting...")
    predictions = model.predict(img_array, verbose=0)
    
    predicted_class = np.argmax(predictions[0])
    confidence = predictions[0][predicted_class]
    
    print("\n" + "=" * 60)
    print("ğŸ“Š PREDICTION RESULT")
    print("=" * 60)
    print(f"Predicted class: {predicted_class}")
    print(f"Confidence:      {confidence:.2%}")
    print("=" * 60)
    
    # Show top-3 predictions
    top3_indices = np.argsort(predictions[0])[-3:][::-1]
    print("\nTop 3 predictions:")
    for idx in top3_indices:
        print(f"  Class {idx}: {predictions[0][idx]:.2%}")
    
    print("\nâœ… Done!")


def main():
    print("\n" + "=" * 60)
    print("ğŸ§ª MODEL TESTING TOOL")
    print("=" * 60)
    print("\nChá»n cháº¿ Ä‘á»™ test:")
    print("  1. Test trÃªn test dataset (evaluation)")
    print("  2. Test trÃªn 1 áº£nh Ä‘Æ¡n láº»")
    print("  0. Exit")
    
    choice = input("\nNháº­p lá»±a chá»n (1/2/0): ").strip()
    
    if choice == '1':
        test_model_on_dataset()
    elif choice == '2':
        test_single_image()
    elif choice == '0':
        print("Bye! ğŸ‘‹")
    else:
        print("âŒ Lá»±a chá»n khÃ´ng há»£p lá»‡!")


if __name__ == '__main__':
    main()
