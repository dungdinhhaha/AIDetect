# ğŸš€ HÆ°á»›ng dáº«n Training ComparisonDetector trÃªn Google Colab

## BÆ°á»›c 1: Má»Ÿ Google Colab

1. Truy cáº­p: https://colab.research.google.com/
2. Táº¡o notebook má»›i: File â†’ New notebook
3. Chá»n GPU Runtime: Runtime â†’ Change runtime type â†’ GPU (T4 hoáº·c cao hÆ¡n)

---

## BÆ°á»›c 2: Kiá»ƒm tra GPU

```python
# Cell 1: Kiá»ƒm tra GPU
!nvidia-smi

import tensorflow as tf
print(f"TensorFlow version: {tf.__version__}")
print(f"GPU devices: {tf.config.list_physical_devices('GPU')}")
print(f"Num GPUs Available: {len(tf.config.list_physical_devices('GPU'))}")
```

---

## BÆ°á»›c 3: Mount Google Drive vÃ  Clone Repository

```python
# Cell 2: Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')
print("âœ“ Google Drive mounted")
```

```python
# Cell 3: Clone repository
!git clone https://github.com/dungdinhhaha/AIDetect.git /content/ComparisonDetector
%cd /content/ComparisonDetector
!git pull
!ls -la
```

---

## BÆ°á»›c 4: Chuáº©n bá»‹ dá»¯ liá»‡u

### Quan trá»ng: Add Data Folder vÃ o My Drive trÆ°á»›c

**TFRecord Data Link**: https://drive.google.com/drive/folders/1b78oDihDz5ZvsqsLmPCAcbwd5dn08MxX

**CÃ¡ch thÃªm shortcut vÃ o My Drive**:
1. Má»Ÿ link folder TFRecord á»Ÿ trÃªn
2. Click chuá»™t pháº£i vÃ o folder `tfdata` â†’ "Add shortcut to Drive"
3. Chá»n "My Drive" â†’ "Add"
4. Folder sáº½ xuáº¥t hiá»‡n trong My Drive cá»§a báº¡n

### Option A: Upload TFRecord tá»« Google Drive

```python
# Cell 4A: Copy TFRecord tá»« Drive
!mkdir -p /content/data/tct

# Copy TFRecord tá»« shared Google Drive folder
# Link: https://drive.google.com/drive/folders/1b78oDihDz5ZvsqsLmPCAcbwd5dn08MxX
# CÃ¡ch 1: Náº¿u Ä‘Ã£ add shortcut vÃ o My Drive
!cp /content/drive/MyDrive/tfdata/tct/*.tfrecord /content/data/tct/ 2>/dev/null || echo "Trying alternative path..."

# CÃ¡ch 2: Náº¿u folder náº±m á»Ÿ Shared with me, cáº§n add to My Drive trÆ°á»›c
# Hoáº·c mount Shared Drives vÃ  copy
!cp -r /content/drive/Shareddrives/*/tfdata/tct/*.tfrecord /content/data/tct/ 2>/dev/null || echo "No TFRecords found"

# Kiá»ƒm tra
!ls -lh /content/data/tct/
```

### Option B: Táº¡o Dummy Data Ä‘á»ƒ Test

```python
# Cell 4B: Táº¡o dummy TFRecord
import tensorflow as tf
import numpy as np

def create_dummy_tfrecord(output_path, num_samples=100):
    """Táº¡o TFRecord giáº£ vá»›i image vÃ  bounding boxes"""
    with tf.io.TFRecordWriter(output_path) as writer:
        for i in range(num_samples):
            # Dummy image (640x640x3)
            img = np.random.randint(0, 255, (640, 640, 3), dtype=np.uint8)
            img_bytes = tf.io.encode_jpeg(img).numpy()
            
            # Dummy boxes vÃ  labels
            num_boxes = np.random.randint(1, 5)
            boxes = np.random.rand(num_boxes, 4).astype(np.float32)
            labels = np.random.randint(1, 12, num_boxes, dtype=np.int64)
            
            feature = {
                'image': tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_bytes])),
                'boxes': tf.train.Feature(float_list=tf.train.FloatList(value=boxes.flatten())),
                'labels': tf.train.Feature(int64_list=tf.train.Int64List(value=labels)),
                'num_boxes': tf.train.Feature(int64_list=tf.train.Int64List(value=[num_boxes])),
            }
            example = tf.train.Example(features=tf.train.Features(feature=feature))
            writer.write(example.SerializeToString())
    print(f"âœ“ Created {output_path} with {num_samples} samples")

# Táº¡o train vÃ  test TFRecord
!mkdir -p /content/data/tct
create_dummy_tfrecord('/content/data/tct/train.tfrecord', num_samples=500)
create_dummy_tfrecord('/content/data/tct/test.tfrecord', num_samples=100)

!ls -lh /content/data/tct/
```

---

## BÆ°á»›c 5: Xem vÃ  TÃ¹y chá»‰nh Config

```python
# Cell 5: Xem config hiá»‡n táº¡i
from configs.config_v2 import ConfigV2

cfg = ConfigV2()
print("ğŸ“‹ Current Configuration:")
print(f"  Data Dir: {cfg.DATA_DIR}")
print(f"  Model Dir: {cfg.MODEL_DIR}")
print(f"  Batch Size: {cfg.BATCH_SIZE}")
print(f"  Epochs: {cfg.EPOCHS}")
print(f"  Learning Rate: {cfg.LEARNING_RATE}")
print(f"  Backbone: {cfg.BACKBONE}")
print(f"  Image Size: {cfg.IMAGE_SIZE}")
print(f"  Num Classes: {cfg.NUM_CLASSES}")
```

```python
# Cell 6: Override config (optional)
cfg.BATCH_SIZE = 1  # Giáº£m batch size náº¿u GPU nhá»
cfg.EPOCHS = 10     # Sá»‘ epochs muá»‘n train
cfg.LEARNING_RATE = 5e-4  # Fine-tune learning rate

print("âœ“ Config updated for Colab")
```

---

## BÆ°á»›c 6: Test Data Pipeline vÃ  Model

```python
# Cell 7: Test data loader
import os
from data.loader_tf2 import build_dataset

tfrecord_paths = tf.io.gfile.glob(os.path.join(cfg.DATA_DIR, '*.tfrecord'))
print(f"Found {len(tfrecord_paths)} TFRecord files")

if tfrecord_paths:
    ds = build_dataset(tfrecord_paths, image_size=cfg.IMAGE_SIZE, batch_size=cfg.BATCH_SIZE)
    
    for images, targets in ds.take(1):
        print(f"âœ“ Data pipeline working")
        print(f"  Images shape: {images.shape}")
        print(f"  Targets keys: {targets.keys()}")
else:
    print("âš  No TFRecords found - will use dummy dataset")
```

```python
# Cell 8: Test model architecture
from models.detector import ComparisonDetector

detector = ComparisonDetector(
    num_classes=cfg.NUM_CLASSES,
    backbone_name=cfg.BACKBONE,
    backbone_weights=cfg.BACKBONE_WEIGHTS
)

dummy_input = tf.random.uniform((1, 640, 640, 3))
boxes, scores = detector(dummy_input, training=False)

print(f"âœ“ Model test passed")
print(f"  Output boxes: {boxes.shape}")
print(f"  Output scores: {scores.shape}")
```

---

## BÆ°á»›c 7: Báº¯t Ä‘áº§u Training ğŸš€

### Option 1: Cháº¡y script training

```python
# Cell 9A: Cháº¡y train_keras.py
!python train_keras.py
```

### Option 2: Train trá»±c tiáº¿p trong notebook

```python
# Cell 9B: Train trong notebook
import os
import tensorflow as tf
from tensorflow.keras import optimizers
from configs.config_v2 import ConfigV2
from data.loader_tf2 import build_dataset
from models.backbone_keras import build_backbone

# Config
cfg = ConfigV2()
os.makedirs(cfg.MODEL_DIR, exist_ok=True)
os.makedirs(cfg.LOG_DIR, exist_ok=True)
os.makedirs(cfg.CHECKPOINT_DIR, exist_ok=True)

# Distribution strategy
strategy = tf.distribute.MirroredStrategy() if cfg.USE_DISTRIBUTE else tf.distribute.get_strategy()

with strategy.scope():
    # Build model
    backbone = build_backbone(cfg.BACKBONE, cfg.BACKBONE_WEIGHTS)
    inputs = backbone.input
    features = backbone(inputs)[-1]
    x = tf.keras.layers.GlobalAveragePooling2D()(features)
    outputs = tf.keras.layers.Dense(cfg.NUM_CLASSES, activation='softmax')(x)
    model = tf.keras.Model(inputs=inputs, outputs=outputs, name='comparison_detector_v2')
    
    # Compile
    opt = optimizers.SGD(learning_rate=cfg.LEARNING_RATE, momentum=cfg.MOMENTUM)
    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Dataset
tfrecord_paths = tf.io.gfile.glob(os.path.join(cfg.DATA_DIR, '*.tfrecord'))
if not tfrecord_paths:
    print('âš  No TFRecords found, using dummy dataset...')
    dummy_images = tf.random.uniform((cfg.BATCH_SIZE, cfg.IMAGE_SIZE[0], cfg.IMAGE_SIZE[1], 3))
    dummy_labels = tf.random.uniform((cfg.BATCH_SIZE,), minval=0, maxval=cfg.NUM_CLASSES, dtype=tf.int32)
    ds = tf.data.Dataset.from_tensor_slices((dummy_images, dummy_labels)).repeat().batch(cfg.BATCH_SIZE)
else:
    ds = build_dataset(tfrecord_paths, image_size=cfg.IMAGE_SIZE, batch_size=cfg.BATCH_SIZE)
    ds = ds.map(lambda img, tgt: (img, tf.zeros((), dtype=tf.int32))).repeat()

# Callbacks
ckpt_cb = tf.keras.callbacks.ModelCheckpoint(
    filepath=os.path.join(cfg.CHECKPOINT_DIR, 'ckpt_{epoch:02d}.weights.h5'),
    save_weights_only=True,
    save_freq='epoch'
)
tb_cb = tf.keras.callbacks.TensorBoard(log_dir=cfg.LOG_DIR)

# Train
print("\nğŸš€ Starting training...\n")
history = model.fit(
    ds, 
    epochs=cfg.EPOCHS, 
    steps_per_epoch=100,  # Äiá»u chá»‰nh theo dataset size
    callbacks=[ckpt_cb, tb_cb]
)

# Save
model.save(os.path.join(cfg.MODEL_DIR, 'model.keras'))
print('\nâœ… Training completed!')
print(f'Model saved to: {cfg.MODEL_DIR}/model.keras')
```

---

## BÆ°á»›c 8: TensorBoard Monitoring (Optional)

```python
# Cell 10: Load TensorBoard
%load_ext tensorboard
%tensorboard --logdir /content/drive/MyDrive/comparison_detector_models_v2/logs
```

---

## BÆ°á»›c 9: ÄÃ¡nh giÃ¡ Model

```python
# Cell 11: Load vÃ  test model
model_path = os.path.join(cfg.MODEL_DIR, 'model.keras')
if os.path.exists(model_path):
    loaded_model = tf.keras.models.load_model(model_path)
    print(f"âœ“ Model loaded from {model_path}")
    
    # Test inference
    test_img = tf.random.uniform((1, 640, 640, 3))
    pred = loaded_model(test_img, training=False)
    print(f"  Prediction shape: {pred.shape}")
    print(f"  Predicted class: {tf.argmax(pred[0]).numpy()}")
else:
    print(f"âš  Model not found at {model_path}")
```

---

## BÆ°á»›c 10: Download Model vá» Local

```python
# Cell 12: Zip vÃ  download
!cd /content/drive/MyDrive && zip -r comparison_detector_models_v2.zip comparison_detector_models_v2/

from google.colab import files
files.download('/content/drive/MyDrive/comparison_detector_models_v2.zip')
```

---

## ğŸ“ Troubleshooting

### âŒ Out of Memory
```python
# Giáº£m batch size vÃ  image size
cfg.BATCH_SIZE = 1
cfg.IMAGE_SIZE = (512, 512)
cfg.BACKBONE = 'resnet50'  # Thay vÃ¬ resnet101
```

### âŒ No TFRecords Found
- Kiá»ƒm tra Ä‘Æ°á»ng dáº«n trong Cell 4A
- Hoáº·c dÃ¹ng Option B Ä‘á»ƒ táº¡o dummy data

### âŒ Model Not Converging
```python
# Giáº£m learning rate
cfg.LEARNING_RATE = 1e-4

# Xem TensorBoard Ä‘á»ƒ debug
%tensorboard --logdir /content/drive/MyDrive/comparison_detector_models_v2/logs
```

### âŒ GPU Disconnected
- Colab free cÃ³ giá»›i háº¡n thá»i gian
- LÆ°u checkpoint thÆ°á»ng xuyÃªn
- NÃ¢ng cáº¥p Colab Pro náº¿u cáº§n train lÃ¢u

---

## ğŸ’¾ Model Ä‘Æ°á»£c lÆ°u táº¡i:

- **Google Drive**: `/content/drive/MyDrive/comparison_detector_models_v2/`
- **Checkpoints**: Má»—i epoch táº¡i `/checkpoints/`
- **TensorBoard logs**: `/logs/`
- **Final model**: `model.keras`

---

## ğŸ“Š Theo dÃµi Training:

1. **Terminal output**: Loss vÃ  accuracy má»—i epoch
2. **TensorBoard**: Graphs chi tiáº¿t
3. **Google Drive**: Auto-save checkpoints

---

**Repository**: https://github.com/dungdinhhaha/AIDetect  
**Author**: dungdinhhaha | dungdinh542004@gmail.com  
**Email**: dungdinh542004@gmail.com

---

## ğŸ¯ Quick Start (Copy-Paste táº¥t cáº£):

```python
# Setup nhanh - paste táº¥t cáº£ vÃ o 1 cell
!git clone https://github.com/dungdinhhaha/AIDetect.git /content/ComparisonDetector
%cd /content/ComparisonDetector

from google.colab import drive
drive.mount('/content/drive')

!mkdir -p /content/data/tct

# Copy TFRecord tá»« Google Drive
# Link data: https://drive.google.com/drive/folders/1b78oDihDz5ZvsqsLmPCAcbwd5dn08MxX
!cp /content/drive/MyDrive/tfdata/tct/*.tfrecord /content/data/tct/ 2>/dev/null || echo "Data not found, check path"
!ls -lh /content/data/tct/

# Train
!python train_keras.py
```

Copy code trÃªn vÃ o Google Colab vÃ  cháº¡y Ä‘á»ƒ báº¯t Ä‘áº§u training ngay! ğŸš€
