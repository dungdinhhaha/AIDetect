{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5428cd8a",
   "metadata": {},
   "source": [
    "## 1) Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f26d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/ComparisonDetector')\n",
    "print('CWD:', os.getcwd())\n",
    "print('List:', os.listdir('.')[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822c94f4",
   "metadata": {},
   "source": [
    "## 2) Install deps (TF 2.15 + KerasCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7172958a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tensorflow==2.15.0 keras==2.15.0 keras-cv==0.6.4 tensorflow-io-gcs-filesystem==0.31.0\n",
    "!pip install -q numpy==1.26.4 opencv-python pillow matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b367aec",
   "metadata": {},
   "source": [
    "## 3) Imports & Label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_cv\n",
    "import numpy as np\n",
    "import os\n",
    "from libs.label_dict import get_label_name_map\n",
    "\n",
    "label_map = get_label_name_map()  # id -> name\n",
    "num_classes = len(label_map)\n",
    "print('Classes:', label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebc5be6",
   "metadata": {},
   "source": [
    "## 4) TFRecord parser (boxes+labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2f1c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfrecord_path = 'tfdata/tct/train.tfrecord'\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    features = {\n",
    "        'img': tf.io.FixedLenFeature([], tf.string),\n",
    "        'img_height': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'img_width': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'gtboxes_and_label': tf.io.FixedLenFeature([], tf.string),\n",
    "        'img_name': tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    parsed = tf.io.parse_single_example(example_proto, features)\n",
    "    h = tf.cast(parsed['img_height'], tf.int32)\n",
    "    w = tf.cast(parsed['img_width'], tf.int32)\n",
    "    img = tf.io.decode_raw(parsed['img'], tf.uint8)\n",
    "    img = tf.reshape(img, [h, w, 3])\n",
    "    # boxes: [x1,y1,x2,y2,label]\n",
    "    gl = tf.io.decode_raw(parsed['gtboxes_and_label'], tf.int32)\n",
    "    gl = tf.reshape(gl, [-1, 5])\n",
    "    boxes_xyxy = tf.cast(gl[:, :4], tf.float32)\n",
    "    labels = tf.cast(gl[:, 4], tf.int32)\n",
    "    # convert to yxyx normalized for KerasCV\n",
    "    y1 = boxes_xyxy[:, 1] / tf.cast(h, tf.float32)\n",
    "    x1 = boxes_xyxy[:, 0] / tf.cast(w, tf.float32)\n",
    "    y2 = boxes_xyxy[:, 3] / tf.cast(h, tf.float32)\n",
    "    x2 = boxes_xyxy[:, 2] / tf.cast(w, tf.float32)\n",
    "    boxes = tf.stack([y1, x1, y2, x2], axis=-1)\n",
    "    return img, boxes, labels\n",
    "\n",
    "def preprocess(img, boxes, labels, image_size=(640,640)):\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    img = tf.image.resize(img, image_size)\n",
    "    return img, { 'boxes': boxes, 'classes': tf.cast(labels, tf.float32) }\n",
    "\n",
    "def load_dataset(batch_size=2, shuffle=512, image_size=(640,640)):\n",
    "    ds = tf.data.TFRecordDataset(tfrecord_path, num_parallel_reads=tf.data.AUTOTUNE)\n",
    "    ds = ds.map(parse_example, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.shuffle(shuffle)\n",
    "    ds = ds.map(lambda i,b,l: preprocess(i,b,l, image_size), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    ds = ds.padded_batch(batch_size,\n",
    "                        padding_values=(0.0, 0.0, -1.0),\n",
    "                        drop_remainder=True)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "train_ds = load_dataset(batch_size=2, image_size=(640,640))\n",
    "print('Dataset ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39094918",
   "metadata": {},
   "source": [
    "## 5) Build RetinaNet model (KerasCV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cd23a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.RetinaNet(\n",
    "    classes=num_classes,\n",
    "    bounding_box_format='yxyx',\n",
    "    backbone='resnet50',\n",
    ")\n",
    "learning_rate = 1e-4\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9)\n",
    "model.compile(optimizer=optimizer, classification_loss='focal', box_loss='smoothl1')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e413921",
   "metadata": {},
   "source": [
    "## 6) Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7e4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "steps_per_epoch = 1000  # chỉnh nếu muốn\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint('detector_retinanet_best.h5', save_best_only=True, monitor='loss', mode='min'),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1),\n",
    "]\n",
    "history = model.fit(train_ds, epochs=epochs, steps_per_epoch=steps_per_epoch, callbacks=callbacks)\n",
    "model.save('detector_retinanet_final.h5')\n",
    "print('Saved detector_retinanet_final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248806b7",
   "metadata": {},
   "source": [
    "## 7) Inference on one image (draw boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59173dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "infer_model = tf.keras.models.load_model('detector_retinanet_best.h5', compile=False)\n",
    "\n",
    "# lấy một sample từ TFRecord\n",
    "raw_sample = next(iter(tf.data.TFRecordDataset(tfrecord_path).map(parse_example).take(1)))\n",
    "img_name = raw_sample['img_name'].numpy().decode('utf-8')\n",
    "h = int(raw_sample['img_height'].numpy())\n",
    "w = int(raw_sample['img_width'].numpy())\n",
    "img = tf.io.decode_raw(raw_sample['img'], tf.uint8)\n",
    "img = tf.reshape(img, [h, w, 3])\n",
    "img_resized = tf.image.resize(tf.cast(img, tf.float32)/255.0, (640,640))\n",
    "pred = infer_model.predict(img_resized[None], verbose=0)\n",
    "boxes = pred['boxes'][0]   # y1,x1,y2,x2 normalized\n",
    "scores = pred['confidence'][0]\n",
    "classes = tf.cast(pred['classes'][0], tf.int32)\n",
    "\n",
    "# filter theo score\n",
    "mask = scores > 0.3\n",
    "boxes = tf.boolean_mask(boxes, mask)\n",
    "scores = tf.boolean_mask(scores, mask)\n",
    "classes = tf.boolean_mask(classes, mask)\n",
    "\n",
    "# vẽ\n",
    "img_draw = Image.fromarray(img.numpy())\n",
    "draw = ImageDraw.Draw(img_draw)\n",
    "for box, sc, cls in zip(boxes.numpy(), scores.numpy(), classes.numpy()):\n",
    "    y1,x1,y2,x2 = box\n",
    "    y1*=h; y2*=h; x1*=w; x2*=w\n",
    "    draw.rectangle([x1,y1,x2,y2], outline='red', width=2)\n",
    "    name = label_map.get(int(cls), str(int(cls)))\n",
    "    draw.text((x1+3, y1+3), f\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_draw)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print('Image:', img_name, 'detections:', len(boxes))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
