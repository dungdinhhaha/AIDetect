# ğŸ”§ HÆ¯á»šNG DáºªN Xá»¬ LÃ SAU KHI TRAIN TRÃŠN COLAB

## ğŸ“Œ Váº¥n Ä‘á» báº¡n gáº·p pháº£i

Training dá»«ng á»Ÿ epoch 7 vÃ¬:
1. **Báº¡n báº¥m Ctrl+C** (chá»§ Ä‘á»™ng dá»«ng)
2. **Dataset háº¿t data** - Warning: `Your input ran out of data`
3. **`steps_per_epoch=500` quÃ¡ lá»›n** cho dataset

---

## âœ… GIáº¢I PHÃP ÄÃƒ FIX

### 1. Update `train_keras.py`:
- âœ… Tá»± Ä‘á»™ng tÃ­nh `steps_per_epoch` dá»±a trÃªn dataset size
- âœ… ThÃªm `.repeat()` Ä‘á»ƒ dataset khÃ´ng bao giá» háº¿t
- âœ… ThÃªm callbacks tá»‘t hÆ¡n: `best_model`, `reduce_lr`
- âœ… Save cáº£ final model vÃ  best model

### 2. Táº¡o `resume_training.py`:
- âœ… Resume tá»« checkpoint cuá»‘i cÃ¹ng
- âœ… Tá»± Ä‘á»™ng detect epoch Ä‘Ã£ train
- âœ… Continue tá»« epoch tiáº¿p theo

---

## ğŸš€ CÃCH Sá»¬ Dá»¤NG TRÃŠN COLAB

### **Option 1: Train tá»« Ä‘áº§u (láº§n Ä‘áº§u)**

```python
# Cell 1: Clone & Setup
!git clone https://github.com/dungdinhhaha/AIDetect.git
%cd AIDetect
!pip install -q -r requirements.txt

# Cell 2: Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# Cell 3: Start Training
!python train_keras.py
```

**Káº¿t quáº£:**
- Model sáº½ tá»± Ä‘á»™ng save má»—i epoch vÃ o `/content/drive/MyDrive/comparison_detector_models_v2/checkpoints/`
- Best model save vÃ o `/content/drive/MyDrive/comparison_detector_models_v2/best_model.h5`
- Final model save vÃ o `/content/drive/MyDrive/comparison_detector_models_v2/final_model.keras`

---

### **Option 2: Resume training (náº¿u bá»‹ ngáº¯t giá»¯a chá»«ng)**

Náº¿u Colab disconnect hoáº·c báº¡n báº¥m Ctrl+C:

```python
# Cell 1: Clone & Setup (náº¿u session má»›i)
!git clone https://github.com/dungdinhhaha/AIDetect.git
%cd AIDetect
!pip install -q -r requirements.txt

# Cell 2: Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# Cell 3: Resume tá»« checkpoint
!python resume_training.py
```

**Script sáº½:**
- âœ… TÃ¬m checkpoint cuá»‘i cÃ¹ng (vd: `ckpt_07.weights.h5`)
- âœ… Load weights
- âœ… Continue tá»« epoch 8 Ä‘áº¿n epoch 20

---

## ğŸ“Š THEO DÃ•I TRAINING

### **1. TensorBoard trong Colab:**

```python
# Load TensorBoard extension
%load_ext tensorboard

# Start TensorBoard
%tensorboard --logdir /content/drive/MyDrive/comparison_detector_models_v2/logs
```

### **2. Kiá»ƒm tra checkpoints:**

```python
!ls -lh /content/drive/MyDrive/comparison_detector_models_v2/checkpoints/
```

### **3. Kiá»ƒm tra model Ä‘Ã£ save:**

```python
import os
model_dir = '/content/drive/MyDrive/comparison_detector_models_v2'
print("ğŸ“ Saved files:")
for f in os.listdir(model_dir):
    path = os.path.join(model_dir, f)
    if os.path.isfile(path):
        size_mb = os.path.getsize(path) / (1024*1024)
        print(f"  - {f}: {size_mb:.1f} MB")
```

---

## ğŸ’¾ SAU KHI TRAINING XONG

### **1. Save káº¿t quáº£ cuá»‘i cÃ¹ng:**

```python
# Cell: Post-Training - Save all artifacts
import json
import shutil
from pathlib import Path

# Paths
model_dir = Path('/content/drive/MyDrive/comparison_detector_models_v2')
archive_dir = model_dir / 'archive_2025_12_05'
archive_dir.mkdir(exist_ok=True)

# Copy models
print("ğŸ“¦ Archiving models...")
shutil.copy(model_dir / 'final_model.keras', archive_dir / 'final_model.keras')
shutil.copy(model_dir / 'best_model.h5', archive_dir / 'best_model.h5')

# Save training config
config_info = {
    'date': '2025-12-05',
    'epochs': 20,
    'batch_size': 2,
    'backbone': 'resnet50',
    'image_size': [640, 640],
    'num_classes': 12,
    'final_loss': float(history.history['loss'][-1]),
    'final_accuracy': float(history.history['accuracy'][-1])
}

with open(archive_dir / 'training_info.json', 'w') as f:
    json.dump(config_info, f, indent=2)

print(f"âœ… Archived to: {archive_dir}")
```

---

### **2. Export model cho deployment:**

```python
# Cell: Export for deployment

# 1. TensorFlow SavedModel (cho FastAPI)
import tensorflow as tf

model = tf.keras.models.load_model('/content/drive/MyDrive/comparison_detector_models_v2/best_model.h5')
export_dir = '/content/drive/MyDrive/comparison_detector_models_v2/saved_model'
model.save(export_dir, save_format='tf')
print(f"âœ… SavedModel exported to: {export_dir}")

# 2. TF Lite (cho mobile/edge devices - optional)
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

tflite_path = '/content/drive/MyDrive/comparison_detector_models_v2/model_quantized.tflite'
with open(tflite_path, 'wb') as f:
    f.write(tflite_model)

print(f"âœ… TFLite model exported to: {tflite_path}")

# 3. Check model size
import os
for name, path in [
    ('Final Keras', '/content/drive/MyDrive/comparison_detector_models_v2/final_model.keras'),
    ('Best H5', '/content/drive/MyDrive/comparison_detector_models_v2/best_model.h5'),
    ('TFLite', tflite_path)
]:
    if os.path.exists(path):
        size_mb = os.path.getsize(path) / (1024*1024)
        print(f"  {name}: {size_mb:.1f} MB")
```

---

### **3. Evaluate model:**

```python
# Cell: Evaluation
from data.loader_tf2 import build_dataset
import numpy as np

# Load test data
test_paths = ['/content/drive/MyDrive/content/data/tct/test.tfrecord']
test_ds = build_dataset(test_paths, image_size=(640, 640), batch_size=2)

# Map to labels
def extract_label(img, tgt):
    return img, tgt['labels'][:, 0]

test_ds = test_ds.map(extract_label).take(100)  # Take 100 batches

# Evaluate
results = model.evaluate(test_ds)
print(f"\nğŸ“Š Test Results:")
print(f"  Loss: {results[0]:.4f}")
print(f"  Accuracy: {results[1]:.4f}")

# Save results
metrics = {
    'test_loss': float(results[0]),
    'test_accuracy': float(results[1])
}

with open('/content/drive/MyDrive/comparison_detector_models_v2/test_metrics.json', 'w') as f:
    json.dump(metrics, f, indent=2)
```

---

### **4. Visualize predictions (sample):**

```python
# Cell: Visualize predictions
import matplotlib.pyplot as plt

# Get one batch
for images, labels in test_ds.take(1):
    predictions = model.predict(images)
    
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    for i in range(2):
        axes[i].imshow(images[i])
        pred_class = np.argmax(predictions[i])
        true_class = labels[i].numpy()
        axes[i].set_title(f'True: {true_class}, Pred: {pred_class}')
        axes[i].axis('off')
    
    plt.tight_layout()
    plt.savefig('/content/drive/MyDrive/comparison_detector_models_v2/sample_predictions.png', dpi=150)
    plt.show()

print("âœ… Saved sample predictions")
```

---

## ğŸ“¥ DOWNLOAD Vá»€ MÃY LOCAL (WINDOWS)

### **Option 1: Download qua Google Drive UI**
1. Má»Ÿ Google Drive
2. VÃ o folder `MyDrive/comparison_detector_models_v2/`
3. Download cÃ¡c file:
   - `best_model.h5` (hoáº·c `final_model.keras`)
   - `saved_model/` (cáº£ folder)
   - `test_metrics.json`

### **Option 2: Download báº±ng code:**

```python
# Cell: Prepare download links
from google.colab import files

# Zip all models
!cd /content/drive/MyDrive/comparison_detector_models_v2 && \
  zip -r models_trained_2025_12_05.zip \
    best_model.h5 \
    final_model.keras \
    test_metrics.json \
    sample_predictions.png

# Download (náº¿u file nhá» < 100MB)
# files.download('/content/drive/MyDrive/comparison_detector_models_v2/models_trained_2025_12_05.zip')

print("âœ… Models zipped! Download from Drive:")
print("   /content/drive/MyDrive/comparison_detector_models_v2/models_trained_2025_12_05.zip")
```

---

## ğŸš€ Sá»¬ Dá»¤NG MODEL LOCAL (WINDOWS)

### **1. Setup local environment:**

```powershell
# PowerShell
cd d:\ComparisonDetector
python -m venv .venv
.\.venv\Scripts\Activate.ps1
pip install -r requirements.txt
```

### **2. Copy model vá»:**

```powershell
# Táº¡o folder models náº¿u chÆ°a cÃ³
New-Item -ItemType Directory -Force -Path "d:\ComparisonDetector\trained_models"

# Copy tá»« Google Drive (sau khi download)
# Giáº£ sá»­ báº¡n download vá» Downloads folder
Copy-Item "$env:USERPROFILE\Downloads\best_model.h5" -Destination "d:\ComparisonDetector\trained_models\"
```

### **3. Test model:**

```python
# test_model.py
import tensorflow as tf
import numpy as np
from PIL import Image

# Load model
model = tf.keras.models.load_model('trained_models/best_model.h5')
print("âœ… Model loaded!")

# Load test image
img = Image.open('test_image.jpg').convert('RGB')
img = img.resize((640, 640))
img_array = np.array(img) / 255.0
img_array = np.expand_dims(img_array, 0)

# Predict
predictions = model.predict(img_array)
predicted_class = np.argmax(predictions[0])
confidence = predictions[0][predicted_class]

print(f"Predicted class: {predicted_class}")
print(f"Confidence: {confidence:.2%}")
```

Cháº¡y:
```powershell
python test_model.py
```

---

## ğŸ› TROUBLESHOOTING

### **Váº¥n Ä‘á» 1: Training dá»«ng giá»¯a chá»«ng**
**Giáº£i phÃ¡p:** Cháº¡y `resume_training.py`

### **Váº¥n Ä‘á» 2: Colab disconnect**
**Giáº£i phÃ¡p:** 
- Free tier: 12 hours max, cáº§n resume
- Pro tier: 24 hours
- Sá»­ dá»¥ng Colab Pro hoáº·c chia nhá» training (10 epochs/láº§n)

### **Váº¥n Ä‘á» 3: Out of memory**
**Giáº£i phÃ¡p:** Giáº£m `BATCH_SIZE` trong `configs/config_v2.py`:
```python
BATCH_SIZE = 1  # Thay vÃ¬ 2
```

### **Váº¥n Ä‘á» 4: Dataset khÃ´ng tÃ¬m tháº¥y**
**Giáº£i phÃ¡p:** Check path trong config:
```python
# configs/config_v2.py
DATA_DIR = "/content/drive/MyDrive/content/data/tct"  # ÄÃºng path
```

---

## âœ… CHECKLIST SAU KHI TRAIN XONG

```
[ ] Training hoÃ n thÃ nh 20 epochs
[ ] Best model saved (best_model.h5)
[ ] Final model saved (final_model.keras)
[ ] TensorBoard logs cÃ³ Ä‘áº§y Ä‘á»§
[ ] Test metrics calculated
[ ] Sample predictions visualized
[ ] Models exported (SavedModel, TFLite)
[ ] Models archived with config
[ ] Models downloaded vá» local
[ ] Test model trÃªn local works
```

---

**Báº¡n ready Ä‘á»ƒ train láº¡i chÆ°a?** ğŸš€

**Lá»‡nh cháº¡y láº¡i trÃªn Colab:**
```python
!python train_keras.py  # Train tá»« Ä‘áº§u
# HOáº¶C
!python resume_training.py  # Resume tá»« checkpoint
```
